{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **학습에 필요한 파일 및 라이브러리 준비**"],"metadata":{"id":"U92X_a8KV6ft"}},{"cell_type":"code","source":["import os\n","import yaml\n","from glob import glob\n","from google.colab import drive\n","import shutil"],"metadata":{"id":"etMk4hAkV33V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 드라이브 마운트\n","drive.mount('/content/drive')\n","\n","# 데이터셋 압축파일 풀기\n","os.makedirs('/content/yolo_dataset/')\n","!unzip -qq '/content/drive/MyDrive/Colab Notebooks/파이널_ZBDS/dataset_main.zip' -d '/content/yolo_dataset/'\n","\n","# yolov5 github clone\n","!git clone https://github.com/ultralytics/yolov5.git\n","\n","# yolov5 구동에 필요한 필수 라이브러리 설치\n","%cd /content/yolov5/\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kes-vHzRVtCJ","executionInfo":{"status":"ok","timestamp":1690516248373,"user_tz":-540,"elapsed":40900,"user":{"displayName":"누노누노","userId":"02523908322137540802"}},"outputId":"188e259d-cd4f-49e8-e399-f90aaac5f320"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Cloning into 'yolov5'...\n","remote: Enumerating objects: 15829, done.\u001b[K\n","remote: Counting objects: 100% (60/60), done.\u001b[K\n","remote: Compressing objects: 100% (55/55), done.\u001b[K\n","remote: Total 15829 (delta 21), reused 26 (delta 5), pack-reused 15769\u001b[K\n","Receiving objects: 100% (15829/15829), 14.59 MiB | 8.47 MiB/s, done.\n","Resolving deltas: 100% (10835/10835), done.\n","/content/yolov5\n","Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n","  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Collecting ultralytics>=8.0.111 (from -r requirements.txt (line 18))\n","  Downloading ultralytics-8.0.143-py3-none-any.whl (604 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.0/605.0 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (16.0.6)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.111->-r requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.7.1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.3.0)\n","Installing collected packages: smmap, gitdb, gitpython, ultralytics, thop\n","Successfully installed gitdb-4.0.10 gitpython-3.1.32 smmap-5.0.0 thop-0.1.1.post2209072238 ultralytics-8.0.143\n"]}]},{"cell_type":"code","source":["# 이미지 경로 설정\n","dataset_path = '/content/yolo_dataset/dataset_main/'\n","train_img_list = glob(dataset_path + '/train/images/*.jpg')\n","valid_img_list = glob(dataset_path + '/valid/images/*.jpg')\n","test_img_list = glob(dataset_path + '/test/images/*.jpg')\n","\n","print('train_img_list : %5s | path : %50s' %(len(train_img_list), dataset_path + '/train/images/'))\n","print('valid_img_list : %5s | path : %50s' %(len(valid_img_list), dataset_path + '/valid/images/'))\n","print('test_img_list  : %5s | path : %50s' %(len(test_img_list), dataset_path + '/test/images/'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690516271803,"user_tz":-540,"elapsed":513,"user":{"displayName":"누노누노","userId":"02523908322137540802"}},"outputId":"5988dac5-5d1b-49fe-fac7-6aaf01327b5f","id":"_LM2s3KxWr9E"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_img_list : 14494 | path :  /content/yolo_dataset/dataset_main//train/images/\n","valid_img_list :  1330 | path :  /content/yolo_dataset/dataset_main//valid/images/\n","test_img_list  :   695 | path :   /content/yolo_dataset/dataset_main//test/images/\n"]}]},{"cell_type":"code","source":["# yolov5s 학습에 필요한 yaml 데이터 생성\n","if not 'yolo_txt' in os.listdir(dataset_path):\n","    os.mkdir(dataset_path + '/yolo_txt')\n","\n","txt_dir = '/content/yolo_dataset/dataset_main/yolo_txt/'\n","\n","with open(txt_dir + 'train.txt', 'w') as f:\n","  f.write('\\n'.join(train_img_list) + '\\n')\n","\n","with open(txt_dir + 'valid.txt', 'w') as f:\n","  f.write('\\n'.join(valid_img_list) + '\\n')\n","\n","with open(txt_dir + 'test.txt', 'w') as f:\n","  f.write('\\n'.join(test_img_list) + '\\n')\n","\n","yaml_data = {\"names\":['back','bottom','error','front','hand','head','side'], #\n","             \"nc\" : 7, # 클래스 수\n","             \"path\" : txt_dir, # root 경로\n","             \"train\" : os.path.join(txt_dir, \"train.txt\"), # train.txt 경로\n","             \"val\" : os.path.join(txt_dir, \"valid.txt\"), # valid.txt 경로\n","             \"test\" : os.path.join(txt_dir,\"test.txt\") # test.txt 경로\n","             }\n","\n","with open(os.path.join(txt_dir, \"data.yaml\"), \"w\") as f:\n","  yaml.dump(yaml_data, f)"],"metadata":{"id":"jD29ccnOmoVR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **YOLOv5s 모델 학습**"],"metadata":{"id":"129_TJV4ZmZ0"}},{"cell_type":"code","source":["%cd /content/yolov5\n","shutil.copyfile('/content/drive/MyDrive/Colab Notebooks/파이널_ZBDS/yolov5s.pt', '/content/yolov5/yolov5s.pt')\n","!python train.py --img 640 \\\n","                 --batch 48 \\\n","                 --epochs 20 \\\n","                 --data /content/yolo_dataset/dataset_main/yolo_txt/data.yaml \\\n","                 --cfg ./models/yolov5s.yaml \\\n","                 --weights ./yolov5s.pt \\\n","                 --exist-ok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690517731144,"user_tz":-540,"elapsed":1057997,"user":{"displayName":"누노누노","userId":"02523908322137540802"}},"outputId":"1ceeb542-bc34-450f-92bf-f76e69e3801a","id":"xIf4Xr7KYwjg"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n","WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n","Note this warning may be related to loading older models. You can update your model to current structure with:\n","    import torch\n","    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n","    torch.save(ckpt, \"updated-model.pt\")\n","\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=./yolov5s.pt, cfg=./models/yolov5s.yaml, data=/content/yolo_dataset/dataset_main/yolo_txt/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=48, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 85.2MB/s]\n","Overriding model.yaml nc=80 with nc=7\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [7, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7038508 parameters, 7038508 gradients, 16.0 GFLOPs\n","\n","Transferred 342/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.000375), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/dataset_main/yolo_txt/train... 14494 images, 4 backgrounds, 0 corrupt: 100% 14494/14494 [00:01<00:00, 7619.83it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_dataset/dataset_main/yolo_txt/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/dataset_main/yolo_txt/valid... 1330 images, 1 backgrounds, 0 corrupt: 100% 1330/1330 [00:00<00:00, 4483.80it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset/dataset_main/yolo_txt/valid.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/19      10.4G    0.06118     0.0262    0.03991        184        640: 100% 302/302 [01:05<00:00,  4.63it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:08<00:00,  1.60it/s]\n","                   all       1330       2106      0.678      0.461      0.419      0.216\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/19        11G     0.0426    0.01638     0.0221        163        640: 100% 302/302 [00:59<00:00,  5.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.83it/s]\n","                   all       1330       2106      0.755      0.864      0.764      0.522\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/19        11G    0.03624    0.01433    0.01514        169        640: 100% 302/302 [00:59<00:00,  5.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.84it/s]\n","                   all       1330       2106       0.93      0.876      0.948      0.678\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/19        11G    0.03075    0.01331    0.01134        154        640: 100% 302/302 [00:59<00:00,  5.04it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.89it/s]\n","                   all       1330       2106      0.949       0.94      0.977      0.752\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/19        11G    0.02821     0.0126   0.009723        137        640: 100% 302/302 [00:59<00:00,  5.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.86it/s]\n","                   all       1330       2106      0.957      0.959       0.98      0.767\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/19        11G    0.02632    0.01186   0.008632        147        640: 100% 302/302 [00:59<00:00,  5.08it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.85it/s]\n","                   all       1330       2106      0.964      0.968      0.984      0.795\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/19        11G    0.02507    0.01138   0.008024        150        640: 100% 302/302 [01:00<00:00,  5.03it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.88it/s]\n","                   all       1330       2106      0.976      0.945      0.984      0.803\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/19        11G    0.02441    0.01111   0.007633        161        640: 100% 302/302 [00:59<00:00,  5.06it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.89it/s]\n","                   all       1330       2106      0.973      0.974      0.988      0.813\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/19        11G    0.02356    0.01074   0.007238        168        640: 100% 302/302 [00:58<00:00,  5.12it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.83it/s]\n","                   all       1330       2106      0.969      0.962      0.986      0.826\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/19        11G    0.02272    0.01047   0.006869        159        640: 100% 302/302 [00:59<00:00,  5.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.85it/s]\n","                   all       1330       2106      0.963      0.972      0.987      0.832\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/19        11G    0.02205    0.01024   0.006387        147        640: 100% 302/302 [00:59<00:00,  5.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.87it/s]\n","                   all       1330       2106      0.975      0.972      0.987      0.827\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/19        11G    0.02149     0.0101   0.006179        174        640: 100% 302/302 [00:59<00:00,  5.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.81it/s]\n","                   all       1330       2106      0.977      0.975      0.989      0.841\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/19        11G    0.02101   0.009719   0.005972        143        640: 100% 302/302 [00:59<00:00,  5.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.85it/s]\n","                   all       1330       2106      0.975      0.982      0.988      0.837\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/19        11G    0.02063   0.009662   0.005918        157        640: 100% 302/302 [00:59<00:00,  5.04it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.87it/s]\n","                   all       1330       2106      0.977      0.979      0.988      0.844\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/19        11G    0.02011   0.009521   0.005646        158        640: 100% 302/302 [00:59<00:00,  5.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.83it/s]\n","                   all       1330       2106      0.974      0.981      0.987      0.851\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/19        11G    0.01956    0.00932   0.005469        159        640: 100% 302/302 [01:00<00:00,  5.03it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.86it/s]\n","                   all       1330       2106      0.979      0.981      0.988      0.853\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/19        11G    0.01909   0.009002   0.005257        127        640: 100% 302/302 [00:59<00:00,  5.11it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.82it/s]\n","                   all       1330       2106      0.977       0.98      0.989      0.852\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/19        11G    0.01872   0.008918   0.004906        151        640: 100% 302/302 [00:59<00:00,  5.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.85it/s]\n","                   all       1330       2106      0.978      0.989       0.99      0.858\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/19        11G    0.01828   0.008721    0.00501        177        640: 100% 302/302 [00:58<00:00,  5.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.82it/s]\n","                   all       1330       2106      0.976      0.985       0.99      0.861\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/19        11G    0.01793    0.00858   0.004918        147        640: 100% 302/302 [00:59<00:00,  5.09it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:07<00:00,  1.87it/s]\n","                   all       1330       2106      0.978      0.989       0.99      0.864\n","\n","20 epochs completed in 0.377 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7029004 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 14/14 [00:10<00:00,  1.31it/s]\n","                   all       1330       2106      0.978      0.989       0.99      0.864\n","                  back       1330        324      0.991      0.995      0.993      0.957\n","                bottom       1330        119       0.99      0.992      0.995      0.909\n","                 error       1330        191      0.959          1      0.976      0.644\n","                 front       1330        409      0.978      0.988      0.989      0.881\n","                  hand       1330        605      0.975      0.993      0.991      0.807\n","                  head       1330        105      0.961      0.962      0.989      0.893\n","                  side       1330        353      0.994      0.994      0.993      0.955\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# **YOLOv5s 모델 테스트**"],"metadata":{"id":"-ELU0XqNk9ON"}},{"cell_type":"code","source":["!unzip -qq '/content/drive/MyDrive/Colab Notebooks/파이널_ZBDS/requirements.zip' -d '/content'"],"metadata":{"id":"vRUmfSGbunjf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python val.py --data /content/yolo_dataset/dataset_main/yolo_txt/data.yaml\\\n","               --weights /content/custom_yolov5s.onnx\\\n","               --exist-ok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4h4rijQbkzPp","executionInfo":{"status":"ok","timestamp":1690518118795,"user_tz":-540,"elapsed":36143,"user":{"displayName":"누노누노","userId":"02523908322137540802"}},"outputId":"c6db8c74-3f8a-4859-a8f8-6b8d47a23264"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n","WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n","Note this warning may be related to loading older models. You can update your model to current structure with:\n","    import torch\n","    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n","    torch.save(ckpt, \"updated-model.pt\")\n","\n","\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolo_dataset/dataset_main/yolo_txt/data.yaml, weights=['/content/custom_yolov5s.onnx'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=True, half=False, dnn=False\n","YOLOv5 🚀 v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\n","Loading /content/custom_yolov5s.onnx for ONNX Runtime inference...\n","Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/dataset_main/yolo_txt/valid.cache... 1330 images, 1 backgrounds, 0 corrupt: 100% 1330/1330 [00:00<?, ?it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1330/1330 [00:23<00:00, 55.94it/s]\n","                   all       1330       2106      0.979      0.986      0.989      0.862\n","                  back       1330        324      0.981      0.994      0.994      0.954\n","                bottom       1330        119      0.989      0.992      0.995      0.914\n","                 error       1330        191      0.969      0.984      0.973      0.629\n","                 front       1330        409      0.981      0.987      0.989       0.88\n","                  hand       1330        605      0.977      0.992      0.992      0.805\n","                  head       1330        105      0.959      0.962      0.988      0.903\n","                  side       1330        353      0.994      0.994      0.993      0.951\n","Speed: 0.2ms pre-process, 8.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/val/exp\u001b[0m\n"]}]}]}